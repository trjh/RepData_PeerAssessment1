---
title: "Reproducible Research: Peer Assessment 1"
output: 
  html_document:
    keep_md: true
---
### Analysis of an individual's activity monitoring data 

## Loading and preprocessing the data

> Show any code that is needed to
> 
> 1. Load the data (i.e. `read.csv()`)
> 
> 1. Process/transform the data (if necessary) into a format suitable for your analysis

The following code will unzip the data file (if neccesary), read it in to
memory, and place the data into a dplyr data frame table.

We may not need it, but for now let's also put the date column into datetime
format with lubridate.

```{r setup_and_load}
library(dplyr, warn.conflicts = FALSE)
library(lubridate)
library(xtable)
library(ggplot2)

## numbers >= 10^6 (4+2) will be denoted in scientific notation,
## and rounded to 2 digits
## http://yihui.name/knitr/demo/output/
## useful for when we print mean & median inline in the next section
options(scipen = 2, digits = 2)

filename="activity.csv"
if(!file.exists(filename)) {
    unzip("activity.zip")
}
if(!file.exists(filename)) {
    stop("Cannot find ",filename," file")
}

activity <- read.csv("activity.csv")

activity <- tbl_df(activity) %>%
    transmute(steps, date = ymd(date), interval)

summary(activity)
```

&nbsp;  <!-- I need more space here than markdown will give me by default! -->


## What is the mean total number of steps taken per day?

> For this part of the assignment, you can ignore the missing values in the dataset.
>
> 1. Calculate the total number of steps taken per day
> 
> 1. Make a histogram of the total number of steps taken each day
> 
> 1. Calculate and report the mean and median of the total number of steps taken per day
  
Now we'll create a table that sums up the number of steps per day.  dplyr
makes this very easy.

We won't remove the missing values from the dataset at this stage, as it makes
it impossible to distinguish between days when we don't have data, and days
when the subject appears to have stayed completely stationary.

```{r dailysummary}
dailysummary <- activity %>%
                group_by(date) %>%
                summarize(steps = sum(steps))

head(dailysummary,3)
```


We'll now create a histogram[^hist] of the number of steps taken per day.
This shows us that the number of steps per day generally resembles a bell
curve, with the mean lying just above the 10,000 steps mark -- however, there
are at least a couple of days where it would appear that the subject did not
move at all.  (Though perhaps, charitabily, we can assume that the subject
left their step-measuring device behind for a day.)

```{r dailysummary_hist}
{
    # histogram with normal distribution curve
    # http://stackoverflow.com/questions/20078107/overlay-normal-curve-to-histogram-in-r
    steps <- dailysummary %>% select(steps) %>% filter(!is.na(steps))
    steps <- steps$steps
    breaks <- 30
    hist1 <- hist(steps, breaks=breaks, main="Histogram of Steps per Day") 
    xfit <- seq(min(steps),max(steps),length=(breaks*3)) 
    yfit <- dnorm(xfit, mean=mean(steps), sd=sd(steps)) 
    yfit <- yfit * diff(hist1$mids[1:2]) * length(steps) 
    lines(xfit, yfit, col="black", lwd=2)
}
```

Finally, we can see that the mean and median number of steps are nearly identical:

```{r dailysummary_avgmed}
meandaily_steps   <- mean(dailysummary$steps, na.rm = TRUE)
mediandaily_steps <- median(dailysummary$steps, na.rm = TRUE)
```

**The mean of the total steps per day is `r meandaily_steps`, and the median is
`r mediandaily_steps`.**

[^hist]: I tend to prefer ggplot2 graphs, but the base plot system seems to
have the cleanest histograms, at least by default.


&nbsp;  <!-- I need more space here than markdown will give me by default! -->


## What is the average daily activity pattern?

> 1. Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
> 1. Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?

There may be a way to do this directly via `qplot()` or `ggplot()` arguments, but
let's keep things simple and make ourselves another summary table.  With this
table, creating the time series plot is easy.

```{r intervalsummary}
intervalsummary <- activity %>%
                    group_by(interval) %>%
                    summarize(meansteps = mean(steps, na.rm = TRUE), medsteps = median(steps, na.rm = TRUE))

qplot(interval, meansteps, geom = "line", data = intervalsummary)
```

The following code shows us that the individual averages the most steps during the interval corresponding to 8:35 in the morning. (**maximum number of steps, on average, at interval == 815**)

```{r intervalsummary_max}
filter(intervalsummary, meansteps == max(meansteps))
```

&nbsp;  <!-- I need more space here than markdown will give me by default! -->


## Imputing missing values

> Note that there are a number of days/intervals where there are missing values (coded as NA). The presence of missing days may introduce bias into some calculations or summaries of the data.
>
> 1. Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)
> 1. Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
> 1. Create a new dataset that is equal to the original dataset but with the missing data filled in.
> 1. Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?

#### Number of missing values in the dataset

```{r missingcounts}
missing <- nrow(filter(activity, is.na(steps)))
missingpercentage <- format((missing / nrow(activity)) * 100, digits = 4)
```

As calculated from the previous code, there are **`r missing` step values missing from the dataset**, representing `r missingpercentage`% of the total rows.  We'll notice later that the dates either have no intervals with `NA` values, or all intervals have `NA` values.  So if we divide the number of missing rows by 288 (24 hours x 60 minutes / 5 minute intervals) we know that we are missing exactly `r missing/288` days worth of data.  This might bias our calculations or summaries if the missing days are unduly skewed towards the weekend or weekday.  A quick look at that here:

```{r missingbias}
activity %>% filter(is.na(steps)) %>% select(date) %>% unique %>% as.vector %>% sapply(weekdays) %>% table
```

We can see that 6/8 of our missing data are in the range Monday to Friday.  This is exactly the proportion of week days we'd expect for 8 missing days -- five-sevenths times eight is `r (5/7)*8`.


#### Divising a NEW strategy for filling in the missing values

My first-pass strategy was to fill in any missing interval with the value of
the average number of steps for that interval across the data set.  This
resulted in negligible change to the data set with regard to mean and median,
but made the central spike in the histogram even higher.  The histogram
resembles a normal distribution, so I'd like to find a strategy that keeps the
histogram reasonably normal, without significantly altering the mean & median
values.[^missingvalues]

To do this, I'll first create seperate interval step profiles for the weekend and the weekday, and then when I'm filling in the missing intervals, I'll use the appropriate day type.  I'll also add the standard distribution to these tables, so that I can use the `rnorm()` function to compute a replacement value, instead of just using the mean.

I thought about using the days surrounding the missing day to bias the missing data calculations, but there seems to be a lot of variance in day-to-day mean step values, so I won't bother.  (See the graph in the *Notes* section)

```{r newstrategy}
daytype <- function(date) {
    dayname <- weekdays(date)
    if (dayname == "Saturday") { "weekend" }
    else if (dayname == "Sunday") { "weekend" }
    else { "weekday" }
}

# update intervalsummary to include daytype -- we don't include median steps
# this time around.  i thought at first  that it might be useful to use in the
# interpolation strategy, but it is not.  i will still include the weekday
# column in case I go back later and make imputation specific to the day of
# the week.
intervalsummary <- activity %>%
                    filter(!is.na(steps)) %>%
                    mutate(weekday = weekdays(date),
                           daytype = vapply(date, daytype, "")) %>%
                    group_by(interval,daytype) %>%
                    summarize(meansteps = mean(steps),
			      sdsteps = sd(steps),
			      min=min(steps),
			      max=max(steps))
```


#### Create a new data set with the missing data filled in

So here we create a short function to replace any NA values -- it requires the
steps, the date, and the interval values as input.  We then use `mapply()` to
pass the steps, date, and interval to this function in order to build
ourselves a new steps column that imputes missing values.  Finally, we use
data.frame and tbl_df to re-assemble an activity table in dplyr data frame
format.

```{r impute2}
set.seed(1001)

complete_steps <- function(steps, date, interval) {
    newsteps <- steps
    daytype <- daytype(date)
    if (is.na(steps)) {
        is_row <- intervalsummary[(intervalsummary$interval == interval) &
				  (intervalsummary$daytype == daytype),]
        #print(is_row)
        newsteps <- round(rnorm(1, mean=is_row$meansteps, sd=is_row$sdsteps))
        # don't let the steps values go below the min or above the max
        if (newsteps > is_row$max) {
            newsteps <- is_row$max
        } else if (newsteps < is_row$min) {
            newsteps <- is_row$min
        }
        #print(newsteps)
    }
    newsteps
}

newactivity <- activity %>%
		mutate(steps = mapply(complete_steps, steps, date, interval))
head(newactivity)
```


#### Histogram, mean, median, and discussion of new data set

Now we make a histogram, and compute the mean and median of the new set.  I
don't expect the mean & median to change, and I hope the histogram will not change much either.

We'll put the new and old mean & median values into a table.  Because it's no
fun to learn stuff on the slides and not use ALL of it!

```{r impute2_effects,results="asis"}
ndailysummary <- newactivity %>%
    	 group_by(date) %>%
		 summarize(steps = sum(steps))

with(ndailysummary, hist(steps,30))

nmeandaily_steps   <- mean(ndailysummary$steps, na.rm = TRUE)
nmediandaily_steps <- median(ndailysummary$steps, na.rm = TRUE)

results <- c(meandaily_steps, nmeandaily_steps,
	     mediandaily_steps, nmediandaily_steps)
dim(results) <- c(2,2)
rownames(results) <- c("orig data", "infilled data")
colnames(results) <- c("mean", "median")
print(xtable(results, center=c("r","r")), type = "html", html.table.attributes="border=0")
```
<br>

We can see that **the mean and median have both increased about 6%** above the values for the unaltered data set.
I suspect that there may be an issue with my usage of `rnorm()` in my imputation strategy, but I can't see it, and the submission deadline is in 20 minutes.  I'm still reasonably convinced that this method is better than using exactly the mean values.  It's more interesting anyway.

The histogram reflects this same shift -- no frequencies on the lower part of the histogram have increased, just frequencies in the second half.

This method *does alter the estimates of the total number of daily steps*, as the mean value has now increased.

One more set of graphs to show us the two histograms, side-by-side

```{r impute2_figure2,fig.width=10}
par(mfrow = c(1,2),
    mar = c(4,4,1,1), oma = c(0,0,2,0))
# mfrow -- 1 row of plots, 2 columns
#  mar  -- margins bottom, left, top, right
#  oma  -- outer margins bottom...

with( dailysummary, hist(steps,30, ylim = c(0,12), main=""))
with(ndailysummary, hist(steps,30, ylim = c(0,12), main=""))
mtext("Comparing histograms of original and imputed data", outer = TRUE)
```

[^missingvalues]: See [MissingValues.md][MissingValues.md] for more rambling
details on my earlier strategies.


&nbsp;  <!-- I need more space here than markdown will give me by default! -->


## Are there differences in activity patterns between weekdays and weekends?
> For this part the `weekdays()` function may be of some help here. Use the dataset with the filled-in missing values for this part.
> 
> 1. Create a new factor variable in the dataset with two levels – “weekday” and “weekend” indicating whether a given date is a weekday or weekend day.
> 1. Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). See the README file in the GitHub repository to see an example of what this plot should look like using simulated data.

As required, we create a new factor variable splitting the weekday and the weekend.  We start with the `weekdays()` function that transforms the date field into a string describing the day of the week (Sunday through Saturday).  We then pass this to an anonymous function, via `sapply()` that returns either "weekday" or "weekend" depending on the output from `weekdays()`. 

I like using `%>%` for this, as we don't have to create a whole string of one-off variables, but the string of processing is clearer than if we nest things like this: third_action(second_action(first_action))

```{r splitweekday_weekend}
daytype <- function(dayname) {
    if (dayname == "Saturday") { "weekend" }
    else if (dayname == "Sunday") { "weekend" }
    else { "weekday" }
}

newactivity <- newactivity %>%
                mutate(weekday = weekdays(date), daytype = vapply(weekday, daytype, ""))
```

Finally we create a table that averages the number of steps taken across each of the 5-minute intervals for daytype="weekday" and daytime="weekend".  We then use this to create the panel plot containing a time series plot of the 5-minute interval vs. average number of steps taken, for weekend days and for weekday days.

```{r splitweekday_plot}
interval_dt_summary <- newactivity %>%
                        group_by(interval, daytype) %>%
                        summarize(meansteps = mean(steps))

plot <- ggplot(interval_dt_summary, aes(interval, meansteps)) +
        geom_line() +
        geom_smooth(method = "loess") +
        facet_grid(daytype ~ .) +
        labs(title = "Activity level over a day, Weekday vs. Weekend",
             y="Average number of Steps",
             x="Interval"
        )
print(plot)
```

It is reasonably clear to see that there are indeed differences in activity pattern between the weekday, when activity starts off strongly at 5:40am, peaks at 8:35am, then tapers to a steady average 50 steps/interval until winding down just before 8:00pm -- and the weekend, where activity ramps more slowly to a peak at 9:15am, and holds at a steadier but more active pace until just around 9:00pm.


&nbsp;  <!-- I need more space here than markdown will give me by default! -->


## Notes
It would be interesting to see if there are different trends for each day of the week, and possibly use those in the imputation strategy.

Here's a graph of the average steps per day across the whole data set, with the X axis markers breaking the data up into week-long chunks.

```{r timeseries_mean_daily_steps}
dt <- qplot(as.Date(date), steps, geom = c("line","point"), data = dailysummary)
print(dt + scale_x_date(breaks = "1 week"))
```
